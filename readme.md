## 

### <center> Anonymised Code for Paper submitted to COLING 2025 - Call for Main Conference Papers </center> ###

## Quick Start

### Set Up Virtual Environment

We run our code on Mac M1, with conda for virtual environment and python version 3.11.3.

To install the requirements
```bash
pip install -r requirements.txt
```

### Running the Code 

The main file to run the pipeline is `src/pipeline.py`. More details on each component can be found below.

#### Code structure

Main components: 
* `keyword_week.py` : this script performs keyword extraction on textual data by leveraging KeyBERT, a state-of-the-art library for extracting keywords and keyphrases. It processes text data organized by date, computes document embeddings, and extracts keywords weekly. The results are saved in CSV files for further analysis.
* `keyword_week.py` : this script focuses on extracting keywords from individual posts within a dataset using KeyBERT. It processes each post to generate document embeddings and keywords, then saves the results in CSV files for each month. It includes progress tracking and error handling for efficient processing.
* `comparer.ipynb` : script that contains the data analysis pipeline to process, analyze, and visualize the comparisong between the different keywords extracted with YAKE, RAKE and KeyBERT and Google Trends. Here's a detailed breakdown of what the code does:

*** Data Loading and Cleaning : Loads keyword extraction data generated by KeyBERT on a daily and weekly basis from CSV files. Cleans the data by replacing instances where no keywords were found with empty lists and converts keyword strings to list objects.
*** Source and Post Data: Loads source data and filtered post data using pickle for YAKE and RAKE keyword extraction methods.
Computes the length of keyword arrays and text summaries for further analysis.
***  Data Merging and Aggregation: Merges data from different sources into a single DataFrame, aligning daily and weekly keyword data with cleaned post data.
***  Weekly Aggregation: Aggregates the merged data on a weekly basis, summarizing counts and sums of keywords extracted by various methods.
*** Trend Analysis: Loads trend data related to keyword scores and percentage increases from Google Trends. Prepares trend data for comparison by aggregating it on a weekly basis.
*** Creates keyword frequency counters for each method (KeyBERT daily, KeyBERT weekly, YAKE, RAKE) and merges them with trend data.
*** Comparative Analysis using the following similarity Metrics:

- Calculates various similarity metrics between trends and keyword counters:
- Jaccard Similarity: Measures the overlap between the top 25 keywords.
- Cosine Distance: Evaluates the cosine similarity between keyword distributions.
- Pearson and Spearman Correlations: Assess linear and rank correlations.
- Kendallâ€™s Tau: Measures ordinal correlation.
- NDCG (Normalized Discounted Cumulative Gain): Evaluates ranking quality.
- Label Ranking Average Precision (LRAP): Measures the precision of ranked labels.
- Histograms and Visualizations: Plots histograms and cumulative distribution functions for the calculated metrics, saving the plots as PDF files for further analysis.

*** Combines results from various similarity and correlation analyses into a single DataFrame.
Generates and saves visualizations comparing different methods in terms of similarity metrics and ranking quality.

* `yake_rake_extraction.ipynb` : this script performs keyword extraction on textual data by leveraging YAKE and RAKE.

### Data used



### Reproducibility



### License

Distributed under the terms of the Apache License 2.0.